name: sgd_ft_RTE
project: zo_bench
command:
  - ${interpreter}
  - ${program}
  - ${args}
  - "--model_name=roberta-large"
  - "--task_name=RTE"
  - "--output_dir=result/RTE-ft-$TAG"
  - "--num_train_epochs=5"
  # - "--per_device_train_batch_size=16"  # TODO  this one should be smaller.
  - "--load_best_model_at_end"
  - "--evaluation_strategy=epoch"
  - "--save_strategy=epoch"
  - "--save_total_limit=1"
  # - "--max_steps=20000"  # TODO  this one should remove
  - "--logging_steps=10"
  - "--num_eval=3000"
  - "--num_train=1743"
  - "--num_dev=747"
  - "--train_as_classification"
  - "--perturbation_mode=two_side"
  - "--trainer=regular"
  - "--optimizer=sgd"
  - "--train_set_seed=0"
  - "--lr_scheduler_type=constant"
  - "--eval_steps=500"
  - "--save_steps=500"
  #  params that were missing. I added according to finetune.sh. All FO methods should follow to update.
  - "--fp16"
  - "--load_float16"
  - "--per_device_train_batch_size=8"
method: grid
metric:
  goal: maximize
  name: test_acc
parameters:
  learning_rate:
    values:
      - 1e-3
      - 1e-4
      - 1e-5
      - 1e-6
      - 1e-7
  weight_decay:
    values:
      - 0

program: run.py